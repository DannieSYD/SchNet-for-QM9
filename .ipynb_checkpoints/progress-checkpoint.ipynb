{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Literature-Review\" data-toc-modified-id=\"Literature-Review-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Literature Review</a></span></li><li><span><a href=\"#SchNet-Implementation\" data-toc-modified-id=\"SchNet-Implementation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>SchNet Implementation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-preparation\" data-toc-modified-id=\"Data-preparation-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Data preparation</a></span></li><li><span><a href=\"#SchNet-model\" data-toc-modified-id=\"SchNet-model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>SchNet model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Expand-the-distance-with-radial-basis-functions:-$e_k(\\mathbf{r}_i-\\mathbf{r}_j)=\\text{exp}(-\\gamma-\\Vert-d_{ij}-\\mu_k-\\Vert-^2),-d_{ij}=\\Vert-\\mathbf{r}_i-\\mathbf{r}_j-\\Vert$\" data-toc-modified-id=\"Expand-the-distance-with-radial-basis-functions:-$e_k(\\mathbf{r}_i-\\mathbf{r}_j)=\\text{exp}(-\\gamma-\\Vert-d_{ij}-\\mu_k-\\Vert-^2),-d_{ij}=\\Vert-\\mathbf{r}_i-\\mathbf{r}_j-\\Vert$-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Expand the distance with radial basis functions: $e_k(\\mathbf{r}_i-\\mathbf{r}_j)=\\text{exp}(-\\gamma \\Vert d_{ij}-\\mu_k \\Vert ^2), d_{ij}=\\Vert \\mathbf{r}_i-\\mathbf{r}_j \\Vert$</a></span></li><li><span><a href=\"#Activation-function\" data-toc-modified-id=\"Activation-function-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Activation function</a></span></li><li><span><a href=\"#Continuous-filter-convolutional-layer.-A-MLP-is-used-for-the-filter-generating-function.-The-aggregate-mode-is-'add'.\" data-toc-modified-id=\"Continuous-filter-convolutional-layer.-A-MLP-is-used-for-the-filter-generating-function.-The-aggregate-mode-is-'add'.-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Continuous-filter convolutional layer. A MLP is used for the filter-generating function. The aggregate mode is 'add'.</a></span></li><li><span><a href=\"#Interaction-block\" data-toc-modified-id=\"Interaction-block-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>Interaction block</a></span></li><li><span><a href=\"#SchNet-Model\" data-toc-modified-id=\"SchNet-Model-2.2.5\"><span class=\"toc-item-num\">2.2.5&nbsp;&nbsp;</span>SchNet Model</a></span></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Evaluation</a></span></li><li><span><a href=\"#Invariance-to-permutation-(atom-indexing)\" data-toc-modified-id=\"Invariance-to-permutation-(atom-indexing)-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Invariance to permutation (atom indexing)</a></span></li><li><span><a href=\"#Invariance-to-rotations\" data-toc-modified-id=\"Invariance-to-rotations-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Invariance to rotations</a></span></li><li><span><a href=\"#Training-Loop\" data-toc-modified-id=\"Training-Loop-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Training Loop</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature Review\n",
    "\n",
    "**[SchNet: A continuous-filter convolutional neural network for modeling quantum interactions](https://arxiv.org/abs/1706.08566)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# SchNet Implementation\n",
    "\n",
    "- Dataset: QM9\n",
    "- Benchmarks: U0 (Internal energy at 0K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from math import pi as PI\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_add_pool, radius_graph, MessagePassing\n",
    "\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "\n",
    "def seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "> **Key steps:**\n",
    "> \n",
    "> - Download data and set target\n",
    "> - Use ```atomref``` to correct the energy of intramolecular interactions\n",
    "> - Transform the unit from eV to kcal/mol to be consistant with the paper\n",
    "> - Normalize the data to improve model generalization\n",
    "> - Split training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dataset = QM9(root='./qm9')\n",
    "\n",
    "    target = 7\n",
    "    KCALMOL2EV = 0.04336414\n",
    "\n",
    "    atomref = dataset.atomref(target)\n",
    "\n",
    "    index = 0\n",
    "    for data in dataset:\n",
    "        y_hat = data.y[:, target] - atomref[data.z].sum()\n",
    "        dataset[index].y[:, target] = y_hat\n",
    "        index += 1\n",
    "\n",
    "    dataset.y = dataset.y//KCALMOL2EV\n",
    "    mean = dataset.y.mean(dim=0, keepdim=True)\n",
    "    std = dataset.y.std(dim=0, keepdim=True)\n",
    "    dataset.y = (dataset.y - mean) / std\n",
    "    mean, std = mean[:, target].item(), std[:, target].item()\n",
    "    print(f\"mean and std values of U0: mean = {mean}, std = {std}\")\n",
    "\n",
    "    train_dataset = dataset[:50000]\n",
    "    test_dataset = dataset[50000:51000]\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=True)\n",
    "    return train_loader, test_loader, mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## SchNet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Expand the distance with radial basis functions: $e_k(\\mathbf{r}_i-\\mathbf{r}_j)=\\text{exp}(-\\gamma \\Vert d_{ij}-\\mu_k \\Vert ^2), d_{ij}=\\Vert \\mathbf{r}_i-\\mathbf{r}_j \\Vert$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class GaussianSmearing(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        start: float = 0.0,\n",
    "        stop: float = 5.0,\n",
    "        num_gaussians: int = 50,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        offset = torch.linspace(start, stop, num_gaussians)\n",
    "        self.coeff = -0.5 / (offset[1] - offset[0]).item()**2\n",
    "        self.register_buffer('offset', offset)\n",
    "\n",
    "    def forward(self, dist: Tensor) -> Tensor:  # dist = d_{ij} range: 0-7\n",
    "        dist = dist.view(-1, 1) - self.offset.view(1, -1)\n",
    "        return torch.exp(self.coeff * torch.pow(dist, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class ShiftedSoftplus(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.shift = torch.log(torch.tensor(2.0)).item()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return F.softplus(x) - self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Continuous-filter convolutional layer. A MLP is used for the filter-generating function. The aggregate mode is 'add'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class CFConv(MessagePassing):\n",
    "    def __init__(self, nn_layers: nn.Sequential, cutoff: float):\n",
    "        super().__init__(aggr='add')\n",
    "        self.cutoff = cutoff\n",
    "        self.nn = nn_layers\n",
    "\n",
    "    def forward(self, h, edge_index, edge_weight, edge_attr):\n",
    "        C = 0.5 * (torch.cos(edge_weight * PI / self.cutoff) + 1.0)\n",
    "        W = self.nn(edge_attr) * C.view(-1, 1)\n",
    "        x = self.propagate(edge_index, x=h, W=W)  # message -> aggregate -> update\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j: Tensor, W: Tensor) -> Tensor:\n",
    "        return x_j * W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Interaction block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Interaction(nn.Module):\n",
    "    def __init__(self, hidden_channels: int, num_gaussians: int, cutoff: float, num_filters: int):\n",
    "        super().__init__()\n",
    "        self.cutoff = cutoff\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_gaussians, hidden_channels),\n",
    "            ShiftedSoftplus(),\n",
    "            nn.Linear(hidden_channels, num_filters),\n",
    "            ShiftedSoftplus(),\n",
    "        )\n",
    "        self.atom_wise = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.conv = CFConv(self.mlp, self.cutoff)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            ShiftedSoftplus(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "        )\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.atom_wise.weight)\n",
    "        self.atom_wise.bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.mlp[0].weight)\n",
    "        self.mlp[0].bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.mlp[2].weight)\n",
    "        self.mlp[2].bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.out[0].weight)\n",
    "        self.out[0].bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.out[2].weight)\n",
    "        self.out[2].bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, h, edge_index, edge_weight, edge_attr):\n",
    "        h = self.atom_wise(h)\n",
    "        h = self.conv(h, edge_index, edge_weight, edge_attr)\n",
    "        h = self.out(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### SchNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class SchNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SchNetModel, self).__init__()\n",
    "        # TODO: Define layers and modules here, for instance:\n",
    "        # self.conv = SomeGeometricLayer()\n",
    "        self.hidden_channels = 128\n",
    "        self.num_interactions = 6\n",
    "        self.num_filters = 128\n",
    "        self.num_gaussians = 50\n",
    "        self.cutoff = 10.0\n",
    "        self.max_num_neighbors = 32\n",
    "\n",
    "        self.embedding = nn.Embedding(100, self.hidden_channels, padding_idx=0)\n",
    "        self.interactions = nn.ModuleList()\n",
    "        for _ in range(self.num_interactions):\n",
    "            block = Interaction(self.hidden_channels, self.num_gaussians, self.cutoff, self.num_filters)\n",
    "            self.interactions.append(block)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.hidden_channels, self.hidden_channels // 2),\n",
    "            ShiftedSoftplus(),\n",
    "            nn.Linear(self.hidden_channels // 2, 1)\n",
    "        )\n",
    "        self.distance_expansion = GaussianSmearing(0.0, self.cutoff, self.num_gaussians)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.embedding.reset_parameters()\n",
    "        for interaction in self.interactions:\n",
    "            interaction.reset_parameters()\n",
    "        torch.nn.init.xavier_uniform_(self.layers[0].weight)\n",
    "        self.layers[0].bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.layers[2].weight)\n",
    "        self.layers[2].bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, data):\n",
    "        pos, z, batch = data.pos, data.z, data.batch\n",
    "\n",
    "        edge_index = radius_graph(pos, r=self.cutoff, batch=batch,\n",
    "                                  max_num_neighbors=self.max_num_neighbors)\n",
    "        row, col = edge_index\n",
    "        edge_weight = (pos[row] - pos[col]).norm(dim=-1)\n",
    "        edge_attr = self.distance_expansion(edge_weight)\n",
    "\n",
    "        x_emb = self.embedding(z)\n",
    "        h = x_emb\n",
    "        for interaction in self.interactions:\n",
    "            h = h + interaction(h, edge_index, edge_weight, edge_attr)\n",
    "        h = self.layers(h)\n",
    "        out = global_add_pool(h, batch)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, epoch, loader, device, mean, std):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_mae = 0\n",
    "    for data in loader:\n",
    "        data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            target = data.y[:, 7].unsqueeze(1)\n",
    "            loss = F.mse_loss(out, target)\n",
    "\n",
    "            out = out*std+mean\n",
    "            target = target*std+mean\n",
    "            mae = torch.sum(torch.abs(target-out)) // len(target)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_mae += mae.item()\n",
    "    loss = total_loss / len(loader)\n",
    "    mae = total_mae / len(loader)\n",
    "    print(f\"------------------------------------ Validation Epoch {epoch+1} {epoch} Loss = {loss:.6f}, MAE = {mae:.6f}\")\n",
    "    return loss, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Invariance to permutation (atom indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def verify_permutation_invariance(model, data):\n",
    "    permuted_data = data.clone()  # Clone to get a new copy\n",
    "    node_permutation = torch.randperm(data.num_nodes)\n",
    "    permuted_data.x = data.x[node_permutation]\n",
    "    if data.edge_index is not None:\n",
    "        edge_index_remap = {i: node_permutation[i].item() for i in range(data.num_nodes)}\n",
    "        permuted_data.edge_index = torch.tensor([[edge_index_remap[i.item()] for i in row] for row in data.edge_index.t()]).t()\n",
    "\n",
    "    return torch.allclose(model(data), model(permuted_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Invariance to rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def rotate_molecule(coordinates, angle, axis):\n",
    "    R = torch.eye(3)\n",
    "    angle = torch.tensor(angle)\n",
    "    c, s = torch.cos(angle), torch.sin(angle)\n",
    "    if axis == 0:  # Rotate around x-axis\n",
    "        R[1, 1], R[1, 2], R[2, 1], R[2, 2] = c, -s, s, c\n",
    "    elif axis == 1:  # Rotate around y-axis\n",
    "        R[0, 0], R[0, 2], R[2, 0], R[2, 2] = c, s, -s, c\n",
    "    elif axis == 2:  # Rotate around z-axis\n",
    "        R[0, 0], R[0, 1], R[1, 0], R[1, 1] = c, -s, s, c\n",
    "    return torch.matmul(coordinates, R)\n",
    "\n",
    "\n",
    "def verify_rotation_invariance(model, data):\n",
    "    rotated_data = data.clone() # Clone to get a new copy\n",
    "    angle = np.random.uniform(0, 2 * np.pi)\n",
    "    axis = np.random.choice([0, 1, 2])\n",
    "    rotated_data.pos = rotate_molecule(data.pos, angle, axis)\n",
    "\n",
    "    return torch.allclose(model(data), model(rotated_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = SchNetModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.96, last_epoch=-1)\n",
    "\n",
    "pretrained = True\n",
    "model_path = 'schnet_energy_model_100.pth'\n",
    "dataset = QM9(root='./qm9')\n",
    "train_loader, test_loader, mean, std = load_data()\n",
    "\n",
    "data = train_loader.dataset[0]\n",
    "print(\"Let us print all the attributes (along with their shapes) that our PyG molecular graph contains:\")\n",
    "print(data)\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "if not pretrained:\n",
    "    for epoch in range(100):\n",
    "        total_loss = 0\n",
    "        total_mae = 0\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            target = data.y[:, 7].unsqueeze(1)\n",
    "\n",
    "            loss = F.mse_loss(out, target)  # Using the 7th property as an example target\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            out = out * std + mean\n",
    "            target = target * std + mean\n",
    "            mae = torch.sum(torch.abs(target - out)) // len(target)\n",
    "            total_loss += loss.item()\n",
    "            total_mae += mae.item()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % 10000 == 0:\n",
    "                scheduler.step()\n",
    "\n",
    "        mse = total_loss / len(train_loader)\n",
    "        mae = total_mae / len(train_loader)\n",
    "        print(f\"Training {epoch} Loss = {loss:.6f}, MAE = {mae:.6f}, LR = {scheduler.get_last_lr()}\")\n",
    "\n",
    "        # Evaluate\n",
    "        loss, test_mae = evaluate_model(model, epoch, test_loader, device, mean, std)\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1} Model Saving ...\")\n",
    "            torch.save(model.state_dict(), f\"schnet_energy_model_{epoch+1}.pth\")\n",
    "else:\n",
    "    model = SchNetModel()\n",
    "    model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sample_data = next(iter(test_loader))\n",
    "print(\"Permutation Invariance:\", verify_permutation_invariance(model, sample_data))\n",
    "print(\"Rotation Invariance:\", verify_rotation_invariance(model, sample_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "167.933px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
