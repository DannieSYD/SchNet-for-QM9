{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Implementation of SchNet on QM9 Dataset with target U0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from math import pi as PI\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_add_pool, radius_graph, MessagePassing\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set Seed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataLoader for QM9 dataset (transform the unit of U0 from eV to kcal/mol and normalize)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dataset = QM9(root='./qm9')\n",
    "\n",
    "    target = 7\n",
    "    KCALMOL2EV = 0.04336414\n",
    "\n",
    "    atomref = dataset.atomref(target)\n",
    "\n",
    "    index = 0\n",
    "    for data in dataset:\n",
    "        y_hat = data.y[:, target] - atomref[data.z].sum()\n",
    "        dataset[index].y[:, target] = y_hat\n",
    "        index += 1\n",
    "\n",
    "    dataset.y = dataset.y//KCALMOL2EV\n",
    "    mean = dataset.y.mean(dim=0, keepdim=True)\n",
    "    std = dataset.y.std(dim=0, keepdim=True)\n",
    "    dataset.y = (dataset.y - mean) / std\n",
    "    mean, std = mean[:, target].item(), std[:, target].item()\n",
    "    print(f\"mean and std values of U0: mean = {mean}, std = {std}\")\n",
    "\n",
    "    train_dataset = dataset[:50000]\n",
    "    test_dataset = dataset[50000:51000]\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=True)\n",
    "    return train_loader, test_loader, mean, std"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SchNet model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Expand the distance with radial basis functions: $e_k(\\mathbf{r}_i-\\mathbf{r}_j)=\\text{exp}(-\\gamma \\Vert d_{ij}-\\mu_k \\Vert ^2), d_{ij}=\\Vert \\mathbf{r}_i-\\mathbf{r}_j \\Vert$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GaussianSmearing(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        start: float = 0.0,\n",
    "        stop: float = 5.0,\n",
    "        num_gaussians: int = 50,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        offset = torch.linspace(start, stop, num_gaussians)\n",
    "        self.coeff = -0.5 / (offset[1] - offset[0]).item()**2\n",
    "        self.register_buffer('offset', offset)\n",
    "\n",
    "    def forward(self, dist: Tensor) -> Tensor:  # dist = d_{ij} range: 0-7\n",
    "        dist = dist.view(-1, 1) - self.offset.view(1, -1)\n",
    "        return torch.exp(self.coeff * torch.pow(dist, 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Activation function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ShiftedSoftplus(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.shift = torch.log(torch.tensor(2.0)).item()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return F.softplus(x) - self.shift"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Continuous-filter convolutional layer. A MLP is used for the filter-generating function. The aggregate mode is 'add'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CFConv(MessagePassing):\n",
    "    def __init__(self, nn_layers: nn.Sequential, cutoff: float):\n",
    "        super().__init__(aggr='add')\n",
    "        self.cutoff = cutoff\n",
    "        self.nn = nn_layers\n",
    "\n",
    "    def forward(self, h, edge_index, edge_weight, edge_attr):\n",
    "        C = 0.5 * (torch.cos(edge_weight * PI / self.cutoff) + 1.0)\n",
    "        W = self.nn(edge_attr) * C.view(-1, 1)\n",
    "        x = self.propagate(edge_index, x=h, W=W)  # message -> aggregate -> update\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j: Tensor, W: Tensor) -> Tensor:\n",
    "        return x_j * W"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Interaction block"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Interaction(nn.Module):\n",
    "    def __init__(self, hidden_channels: int, num_gaussians: int, cutoff: float, num_filters: int):\n",
    "        super().__init__()\n",
    "        self.cutoff = cutoff\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_gaussians, hidden_channels),\n",
    "            ShiftedSoftplus(),\n",
    "            nn.Linear(hidden_channels, num_filters),\n",
    "            ShiftedSoftplus(),\n",
    "        )\n",
    "        self.atom_wise = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.conv = CFConv(self.mlp, self.cutoff)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            ShiftedSoftplus(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "        )\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.atom_wise.weight)\n",
    "        self.atom_wise.bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.mlp[0].weight)\n",
    "        self.mlp[0].bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.mlp[2].weight)\n",
    "        self.mlp[2].bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.out[0].weight)\n",
    "        self.out[0].bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.out[2].weight)\n",
    "        self.out[2].bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, h, edge_index, edge_weight, edge_attr):\n",
    "        h = self.atom_wise(h)\n",
    "        h = self.conv(h, edge_index, edge_weight, edge_attr)\n",
    "        h = self.out(h)\n",
    "        return h"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SchNet Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SchNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SchNetModel, self).__init__()\n",
    "        # TODO: Define layers and modules here, for instance:\n",
    "        # self.conv = SomeGeometricLayer()\n",
    "        self.hidden_channels = 128\n",
    "        self.num_interactions = 6\n",
    "        self.num_filters = 128\n",
    "        self.num_gaussians = 50\n",
    "        self.cutoff = 10.0\n",
    "        self.max_num_neighbors = 32\n",
    "\n",
    "        self.embedding = nn.Embedding(100, self.hidden_channels, padding_idx=0)\n",
    "        self.interactions = nn.ModuleList()\n",
    "        for _ in range(self.num_interactions):\n",
    "            block = Interaction(self.hidden_channels, self.num_gaussians, self.cutoff, self.num_filters)\n",
    "            self.interactions.append(block)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.hidden_channels, self.hidden_channels // 2),\n",
    "            ShiftedSoftplus(),\n",
    "            nn.Linear(self.hidden_channels // 2, 1)\n",
    "        )\n",
    "        self.distance_expansion = GaussianSmearing(0.0, self.cutoff, self.num_gaussians)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.embedding.reset_parameters()\n",
    "        for interaction in self.interactions:\n",
    "            interaction.reset_parameters()\n",
    "        torch.nn.init.xavier_uniform_(self.layers[0].weight)\n",
    "        self.layers[0].bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.layers[2].weight)\n",
    "        self.layers[2].bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, data):\n",
    "        pos, z, batch = data.pos, data.z, data.batch\n",
    "\n",
    "        edge_index = radius_graph(pos, r=self.cutoff, batch=batch,\n",
    "                                  max_num_neighbors=self.max_num_neighbors)\n",
    "        row, col = edge_index\n",
    "        edge_weight = (pos[row] - pos[col]).norm(dim=-1)\n",
    "        edge_attr = self.distance_expansion(edge_weight)\n",
    "\n",
    "        x_emb = self.embedding(z)\n",
    "        h = x_emb\n",
    "        for interaction in self.interactions:\n",
    "            h = h + interaction(h, edge_index, edge_weight, edge_attr)\n",
    "        h = self.layers(h)\n",
    "        out = global_add_pool(h, batch)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_model(model, epoch, loader, device, mean, std):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_mae = 0\n",
    "    for data in loader:\n",
    "        data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            target = data.y[:, 7].unsqueeze(1)\n",
    "            loss = F.mse_loss(out, target)\n",
    "\n",
    "            out = out*std+mean\n",
    "            target = target*std+mean\n",
    "            mae = torch.sum(torch.abs(target-out)) // len(target)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_mae += mae.item()\n",
    "    loss = total_loss / len(loader)\n",
    "    mae = total_mae / len(loader)\n",
    "    print(f\"------------------------------------ Validation Epoch {epoch+1} {epoch} Loss = {loss:.6f}, MAE = {mae:.6f}\")\n",
    "    return loss, mae"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Invariance to permutation (atom indexing)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def verify_permutation_invariance(model, data):\n",
    "    permuted_data = data.clone()  # Clone to get a new copy\n",
    "    node_permutation = torch.randperm(data.num_nodes)\n",
    "    permuted_data.x = data.x[node_permutation]\n",
    "    if data.edge_index is not None:\n",
    "        edge_index_remap = {i: node_permutation[i].item() for i in range(data.num_nodes)}\n",
    "        permuted_data.edge_index = torch.tensor([[edge_index_remap[i.item()] for i in row] for row in data.edge_index.t()]).t()\n",
    "\n",
    "    return torch.allclose(model(data), model(permuted_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Invariance to rotations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rotate_molecule(coordinates, angle, axis):\n",
    "    R = torch.eye(3)\n",
    "    angle = torch.tensor(angle)\n",
    "    c, s = torch.cos(angle), torch.sin(angle)\n",
    "    if axis == 0:  # Rotate around x-axis\n",
    "        R[1, 1], R[1, 2], R[2, 1], R[2, 2] = c, -s, s, c\n",
    "    elif axis == 1:  # Rotate around y-axis\n",
    "        R[0, 0], R[0, 2], R[2, 0], R[2, 2] = c, s, -s, c\n",
    "    elif axis == 2:  # Rotate around z-axis\n",
    "        R[0, 0], R[0, 1], R[1, 0], R[1, 1] = c, -s, s, c\n",
    "    return torch.matmul(coordinates, R)\n",
    "\n",
    "\n",
    "def verify_rotation_invariance(model, data):\n",
    "    rotated_data = data.clone() # Clone to get a new copy\n",
    "    angle = np.random.uniform(0, 2 * np.pi)\n",
    "    axis = np.random.choice([0, 1, 2])\n",
    "    rotated_data.pos = rotate_molecule(data.pos, angle, axis)\n",
    "\n",
    "    return torch.allclose(model(data), model(rotated_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = SchNetModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.96, last_epoch=-1)\n",
    "\n",
    "pretrained = True\n",
    "model_path = 'schnet_energy_model_100.pth'\n",
    "dataset = QM9(root='./qm9')\n",
    "train_loader, test_loader, mean, std = load_data()\n",
    "\n",
    "data = train_loader.dataset[0]\n",
    "print(\"Let us print all the attributes (along with their shapes) that our PyG molecular graph contains:\")\n",
    "print(data)\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "if not pretrained:\n",
    "    for epoch in range(100):\n",
    "        total_loss = 0\n",
    "        total_mae = 0\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            target = data.y[:, 7].unsqueeze(1)\n",
    "\n",
    "            loss = F.mse_loss(out, target)  # Using the 7th property as an example target\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            out = out * std + mean\n",
    "            target = target * std + mean\n",
    "            mae = torch.sum(torch.abs(target - out)) // len(target)\n",
    "            total_loss += loss.item()\n",
    "            total_mae += mae.item()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % 10000 == 0:\n",
    "                scheduler.step()\n",
    "\n",
    "        mse = total_loss / len(train_loader)\n",
    "        mae = total_mae / len(train_loader)\n",
    "        print(f\"Training {epoch} Loss = {loss:.6f}, MAE = {mae:.6f}, LR = {scheduler.get_last_lr()}\")\n",
    "\n",
    "        # Evaluate\n",
    "        loss, test_mae = evaluate_model(model, epoch, test_loader, device, mean, std)\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1} Model Saving ...\")\n",
    "            torch.save(model.state_dict(), f\"schnet_energy_model_{epoch+1}.pth\")\n",
    "else:\n",
    "    model = SchNetModel()\n",
    "    model.load_state_dict(torch.load(model_path))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_data = next(iter(test_loader))\n",
    "print(\"Permutation Invariance:\", verify_permutation_invariance(model, sample_data))\n",
    "print(\"Rotation Invariance:\", verify_rotation_invariance(model, sample_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
